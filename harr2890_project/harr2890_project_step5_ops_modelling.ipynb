{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeff13b0",
   "metadata": {},
   "source": [
    "# Using Historical Data to Predict Batting Success: Step 5 of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745ff8b",
   "metadata": {},
   "source": [
    "Authored by: Donna J. Harris (994042890)\n",
    "\n",
    "Email: harr2890@mylaurier.ca\n",
    "\n",
    "For: CP640 Machine Learning (S22) with Professor Elham Harirpoush"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0057d",
   "metadata": {},
   "source": [
    "## Notebook Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a469b9",
   "metadata": {},
   "source": [
    "Just a word about the presentation of this project code.\n",
    "\n",
    "The code is organized into a series of locally executed Jupyter notebooks, organized by step and needing to be executed in sequence to follow the flow of the entire project.\n",
    "\n",
    "This is `harr2890_project_step5_ops_modelling`, the fifth of five notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943711d9",
   "metadata": {},
   "source": [
    "## *Step 5 - Exploration and Modelling for an OPS Approach*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6c06a",
   "metadata": {},
   "source": [
    "Baseball is full of statistics but one of the clearest statistics about a batter's effectiveness at the plate is the OPS, which is the sum of the player's On Base Percentage (an important indication of how often they get on base) and the player's Slugging Percentage (an indicator of the hitting power a player posesses, which can point to their ability to help their on-base teammates to score).\n",
    "\n",
    "This approach for predicting batting success goes directly to this statistic and aims to explore how past data might have hints about a player's future with respect to the OPS statistic.\n",
    "\n",
    "Generally speaking, a player with an OPS above 0.7666 is above average, with higher values classifying the player as increasingly excellent.  (Reference: https://en.wikipedia.org/wiki/On-base_plus_slugging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f3efd",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb745bba",
   "metadata": {},
   "source": [
    "Import and establish environment for our work, including showing all dataframe column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a32128",
   "metadata": {},
   "source": [
    "### Pre-Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40487b6",
   "metadata": {},
   "source": [
    "Steps 1 and 4 must be run completely before running this notebook.\n",
    "\n",
    "The `data` folder must exist with the following prepared data file:\n",
    "- `./data/step4_ops_data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a8c98",
   "metadata": {},
   "source": [
    "##  Loading Prepared Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28423f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata_csv = \"./data/step4_ops_data.csv\"\n",
    "all_data = pd.read_csv(alldata_csv)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f78c2dd",
   "metadata": {},
   "source": [
    "### Examining Relationships Between Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec6159",
   "metadata": {},
   "source": [
    "The data used in this approach is much more straightforward than in the Hall of Fame Approach. We're looking at past OPS values to predict future OPS values. But we want to know which ones to pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba000abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_plot(feature, target):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(\n",
    "        all_data[feature],\n",
    "        all_data[target],\n",
    "        c='lightgreen',        \n",
    "        edgecolors=(0, 0, 0)\n",
    "    )\n",
    "    \n",
    "    plt.xlim(0.0, 5.2)\n",
    "#     plt.ylim(0.0, 1.4)\n",
    "\n",
    "\n",
    "    plt.xlabel(\"{}\".format(feature))\n",
    "    plt.ylabel(\"{}\".format(target))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f3449",
   "metadata": {},
   "source": [
    "First, we'll see what we should use to predict the OPS of a player's sixth season, given they have played five seasons already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1736a32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter_plot('OPS Y1', 'OPS Y6')\n",
    "scatter_plot('OPS Y2', 'OPS Y6')\n",
    "scatter_plot('OPS Y3', 'OPS Y6')\n",
    "scatter_plot('OPS Y4', 'OPS Y6')\n",
    "scatter_plot('OPS Y5', 'OPS Y6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28505c5",
   "metadata": {},
   "source": [
    "We can see there is a tighter line forming the closer we get to the sixth year. In particular, years three through five are of interest.\n",
    "\n",
    "Next we'll look at the first five seasons with respect to the tenth season's OPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eebcc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter_plot('OPS Y1', 'OPS Y10')\n",
    "scatter_plot('OPS Y2', 'OPS Y10')\n",
    "scatter_plot('OPS Y3', 'OPS Y10')\n",
    "scatter_plot('OPS Y4', 'OPS Y10')\n",
    "scatter_plot('OPS Y5', 'OPS Y10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6b6d3",
   "metadata": {},
   "source": [
    "Here, we see a similar pattern with the OPS values from seasons closer to the tenth season seem to have more definition, however it isn't as tightly formed in the plots as with the sixth season.\n",
    "\n",
    "Finally, we'll look for relationships with the overall career OPS of a player. (Keeping in mind that this represents a value for both completed and in-progress careers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68d24e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter_plot('OPS Y1', 'Career OPS')\n",
    "scatter_plot('OPS Y2', 'Career OPS')\n",
    "scatter_plot('OPS Y3', 'Career OPS')\n",
    "scatter_plot('OPS Y4', 'Career OPS')\n",
    "scatter_plot('OPS Y5', 'Career OPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e711f0",
   "metadata": {},
   "source": [
    "We see much tigheter lines forming up for the career OPS values, especially for the third, fourth, and fifth sesaons, than we do for the others.\n",
    "\n",
    "I'm surprised by these results. I anticipated the 6th season OPS and/or the 10th season OPS value to be more strongly correalated than the Career OPS, but it looks like Career OPS is more strongly related. I thought it would be stronger between consecutive seasons than this tends to indicate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90cb9eb",
   "metadata": {},
   "source": [
    "Let's build three models, both with the 3rd, 4th, and 5th season OPS values as features.\n",
    "\n",
    "Model 1 (M1) will aim to predict the 6th season OPS.\n",
    "Model 2 (M2) will aim to predict the 10th season OPS.\n",
    "Model 3 (M3) will aim to predict the player's Career OPS.\n",
    "\n",
    "Based on these plots, we might expect to see the most accuracy with M3. Let's try and see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e2dd6",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11966207",
   "metadata": {},
   "source": [
    "First, we'll build the dataframes, features, and targets we need. This will be used as X for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e967e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[['OPS Y3', 'OPS Y4', 'OPS Y5']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a40f8a",
   "metadata": {},
   "source": [
    "Next, we need three target array, which will be numbered to make the model they correspond with.\n",
    "\n",
    "The target array for `'OPS Y6'` (Model 1) is `y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489158a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = all_data['OPS Y6']\n",
    "y1 = y1.values\n",
    "y1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b2e37",
   "metadata": {},
   "source": [
    "The target array for `'OPS Y10'` (Model 2) is `y2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = all_data['OPS Y10']\n",
    "y2 = y2.values\n",
    "y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4d531",
   "metadata": {},
   "source": [
    "The target array for `'Career OPS'` (Model 3) is `y3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = all_data['Career OPS']\n",
    "y3 = y3.values\n",
    "y3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d952c80",
   "metadata": {},
   "source": [
    "## Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc22ead",
   "metadata": {},
   "source": [
    "The following is a model evaluation function that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_model_evaluation(name, y, actual, predicted):\n",
    "    \n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    rmse = (np.sqrt(mean_squared_error(actual, predicted)))\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    print(\"Model Performance\\n\")\n",
    "\n",
    "    print('MAE\\t= %.3f' % (mae))\n",
    "    print('RMSE\\t= %.3f' % (rmse))\n",
    "    print('R^2\\t= %.3f' % (r2))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(actual, predicted, edgecolors=(0, 0, 0))\n",
    "    ax.plot([y.min(), y.max()], [y.min(), y.max()], \"k--\", lw=1)\n",
    "    title = \"Measured vs. Predicted\\n(\" + name + \")\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Measured\")\n",
    "    ax.set_ylabel(\"Predicted\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f891cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_r2(model_name, r2, results):\n",
    "    results.append([model_name, r2])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b76ba",
   "metadata": {},
   "source": [
    "### Model 1 (M1) - Predicting Y6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d044ea",
   "metadata": {},
   "source": [
    "We'll split the data into three sets for this approach, training, validation, and testing.\n",
    "\n",
    "Then, create our linear regression model using `'OPS Y3'`, `'OPS Y4'`, and `'OPS Y5'` to predict `'OPS Y6'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0717ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.3, random_state = 42)\n",
    "X_validate, X_test, y1_validate, y1_test = train_test_split(X_test, y1_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "M1 = LinearRegression()\n",
    "M1.fit(X_train, y1_train)\n",
    "\n",
    "y1_predict_validate = M1.predict(X_validate)\n",
    "\n",
    "print_model_evaluation('OPS Y6', y1, y1_validate, y1_predict_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a7be3",
   "metadata": {},
   "source": [
    "### Model 2 (M2) - Predicting Y10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed7607",
   "metadata": {},
   "source": [
    "We'll split the data into three sets for this approach, training, validation, and testing.\n",
    "\n",
    "Then, create our linear regression model using `'OPS Y3'`, `'OPS Y4'`, and `'OPS Y5'` to predict `'OPS Y10'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.3, random_state = 42)\n",
    "X_validate, X_test, y2_validate, y2_test = train_test_split(X_test, y2_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "M2 = LinearRegression()\n",
    "M2.fit(X_train, y2_train)\n",
    "\n",
    "y2_predict_validate = M2.predict(X_validate)\n",
    "\n",
    "print_model_evaluation('OPS Y10', y2, y2_validate, y2_predict_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8642e53",
   "metadata": {},
   "source": [
    "### Model 3 (M3) - Predicting Career OPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15afc223",
   "metadata": {},
   "source": [
    "We'll split the data into three sets for this approach, training, validation, and testing.\n",
    "\n",
    "Then, create our linear regression model using `'OPS Y3'`, `'OPS Y4'`, and `'OPS Y5'` to predict `'Career OPS'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298bb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y3_train, y3_test = train_test_split(X, y3, test_size = 0.3, random_state = 42)\n",
    "X_validate, X_test, y3_validate, y3_test = train_test_split(X_test, y3_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "M3 = LinearRegression()\n",
    "M3.fit(X_train, y3_train)\n",
    "\n",
    "y3_predict_validate = M3.predict(X_validate)\n",
    "\n",
    "print_model_evaluation('Career OPS', y3, y3_validate, y3_predict_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5cf50",
   "metadata": {},
   "source": [
    "After observing the results of the initial three models, we can see a very strong linear correalation but also the strongest predictor is clear. For the remainder of this approach, we will continue to attempt to develop a model which will predict career batting success based on third, fourth, and fifth year OPS statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58064e32",
   "metadata": {},
   "source": [
    "## Improving M3 - Predicting Career OPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081d89d",
   "metadata": {},
   "source": [
    "Let's capture the R-Squared values for our M3 variants in `M3_results`, then try to improve on the M3 prediction approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = []\n",
    "M3_results = store_r2(\"Lin Reg\", r2_score(y3_validate, y3_predict_validate), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b203476",
   "metadata": {},
   "source": [
    "### M3 - SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592f08e",
   "metadata": {},
   "source": [
    "Looking first at a Stochastic Gradient Descent regressor, we'll run `GridSearchCV` first to see if we can locate any some helpful parameters for tuning, before training this variant of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81151aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "tuned_parameters = [\n",
    "    {\"learning_rate\": [\"optimal\"], \"alpha\": [0.1, 0.01, 1e-3, 1e-4], \"max_iter\": [2000]}\n",
    "]\n",
    "\n",
    "scores = [\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\"]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"#### Tuning Hyper-Parameters for\",score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SGDRegressor(), tuned_parameters, scoring=\"%s\" % score)\n",
    "    clf.fit(X, y3)\n",
    "\n",
    "    print(\"Best parameters on dataset (X):\",clf.best_params_)\n",
    "    print(\"\\nGrid scores on dataset (X):\")\n",
    "    means = clf.cv_results_[\"mean_test_score\"]\n",
    "    stds = clf.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "        print(\"\\t%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8190fd3",
   "metadata": {},
   "source": [
    "Now, to use the identified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c6905",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "M3_SDG = SGDRegressor(learning_rate='optimal', alpha=0.001, max_iter=2000)\n",
    "M3_SDG.fit(X_train, y3_train)\n",
    "\n",
    "y3_predict_validate = M3_SDG.predict(X_validate)\n",
    "\n",
    "print_model_evaluation('Career OPS', y3, y3_validate, y3_predict_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef230aff",
   "metadata": {},
   "source": [
    "This isn't much different, but we'll add it to our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0743231",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"SDG Reg\", r2_score(y3_validate, y3_predict_validate), M3_results)\n",
    "M3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed114d4",
   "metadata": {},
   "source": [
    "Let's try cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ec1d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(M3_SDG, X, y3, cv=50, scoring='r2')\n",
    "scores['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a45f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fe034",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"SDG +CV\", np.mean(scores['test_score']), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd862d",
   "metadata": {},
   "source": [
    "Not much different here either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ad93e",
   "metadata": {},
   "source": [
    "### M3 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea86b55",
   "metadata": {},
   "source": [
    "Next is Gradient Boosting. This one is a good candidate for improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be587320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "M3_GradBoost = GradientBoostingRegressor()\n",
    "M3_GradBoost.fit(X_train, y3_train)\n",
    "\n",
    "y3_predict_validate = M3_GradBoost.predict(X_validate)\n",
    "\n",
    "print_model_evaluation('Career OPS', y3, y3_validate, y3_predict_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b7299e",
   "metadata": {},
   "source": [
    "The R-squared value has increased a little and the error values remain low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"GradBoost\", r2_score(y3_validate, y3_predict_validate), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17f83c",
   "metadata": {},
   "source": [
    "Let's cross validate, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff67cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(M3_GradBoost, X, y3, cv=50, scoring='r2')\n",
    "scores['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f663c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a0504",
   "metadata": {},
   "source": [
    "Not a big change, but a small increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af685a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"GradBoost +CV\", np.mean(scores['test_score']), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4301a",
   "metadata": {},
   "source": [
    "### M5 - Grad Boost w/ K-Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe5f32",
   "metadata": {},
   "source": [
    "Returning to Gradient Boosting, we'll try with K-fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76721a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "M3_GradBoost_K = GradientBoostingRegressor()\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "n_scores = cross_val_score(M3_GradBoost_K, X_train, y3_train, scoring='r2', cv=10, n_jobs=-1, error_score='raise')\n",
    "\n",
    "M3_GradBoost_K.fit(X_train, y3_train)\n",
    "\n",
    "y3_predict_validate = M3_GradBoost_K.predict(X_validate)\n",
    "\n",
    "print_model_evaluation('Career OPS', y3, y3_validate, y3_predict_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae307b",
   "metadata": {},
   "source": [
    "About the same as without, which seems to be the trend with our very linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"GradBoost_K\", r2_score(y3_validate, y3_predict_validate), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029d416",
   "metadata": {},
   "source": [
    "And cross-validating,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5576487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(M3_GradBoost_K, X, y3, cv=50, scoring='r2')\n",
    "scores['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c468b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafca67",
   "metadata": {},
   "source": [
    "Very much in the same vein once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d15d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"GradBoostK +CV\", np.mean(scores['test_score']), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0fa010",
   "metadata": {},
   "source": [
    "### M3 - SVR with GridSearchCV results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0dd70",
   "metadata": {},
   "source": [
    "Looking in a different direction with a Support Vector Machine, but first using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]},\n",
    "    {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]},\n",
    "]\n",
    "\n",
    "scores = [\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\"]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"#### Tuning Hyper-Parameters for\",score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVR(), tuned_parameters, scoring=\"%s\" % score)\n",
    "    clf.fit(X, y3)\n",
    "\n",
    "    print(\"Best parameters on dataset (X):\",clf.best_params_)\n",
    "    print(\"\\nGrid scores on dataset (X):\")\n",
    "    means = clf.cv_results_[\"mean_test_score\"]\n",
    "    stds = clf.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "        print(\"\\t%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b57ac",
   "metadata": {},
   "source": [
    "And then using the 'best' parameters identified in our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74316a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "M3_SVR_Grid = SVR(kernel='rbf', gamma=0.001, C=1000)\n",
    "M3_SVR_Grid.fit(X_train, y3_train)\n",
    "\n",
    "y3_predict_validate = M3_SVR_Grid.predict(X_validate)\n",
    "\n",
    "print_model_evaluation('Career OPS', y3, y3_validate, y3_predict_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803efea",
   "metadata": {},
   "source": [
    "These results are higher than most so far, but not better than GradientBoosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"SVR_Grid\", r2_score(y3_validate, y3_predict_validate), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf09f44",
   "metadata": {},
   "source": [
    "Cross-validating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5721fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(M3_SVR_Grid, X, y3, cv=50, scoring='r2')\n",
    "scores['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff92914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502d2ee",
   "metadata": {},
   "source": [
    "And, once again, no big changes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0609be",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_results = store_r2(\"SVR_Grid +CV\", np.mean(scores['test_score']), M3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dbea99",
   "metadata": {},
   "source": [
    "### Summary of M3 variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d146421",
   "metadata": {},
   "source": [
    "To recap, here are the models and also the mean R-squared value after cross validating (+CV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785da837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in M3_results:\n",
    "    print(row[0],\"\\tR^2 = \",row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadee40a",
   "metadata": {},
   "source": [
    "The GradientBoosting regressors provided the most, albeit marginal, improvement to our models and the R-squared value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1458a",
   "metadata": {},
   "source": [
    "## Model Evaluation with Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb9b2a1",
   "metadata": {},
   "source": [
    "Now that we have some models with somewhat improved R-scores, we can make use of the `y3_test` data that was split up to evaluate the models with totally unseen data.\n",
    "\n",
    "GradBoosting and GradBoosting with KFold validation are pretty close, so we'll take a quick look at both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5fd8e",
   "metadata": {},
   "source": [
    "### M3 using GradBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_predict_test = M3_GradBoost.predict(X_test)\n",
    "\n",
    "print_model_evaluation('Career OPS', y3, y3_test, y3_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ef1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_predict_test = M3_GradBoost_K.predict(X_test)\n",
    "\n",
    "print_model_evaluation('Career OPS', y3, y3_test, y3_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb76352f",
   "metadata": {},
   "source": [
    "Again, these results remain pretty similar to one another and also, although slightly lower than our validation scores, is still relatively close to what we saw earlier. There isn't much variance, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22419d4",
   "metadata": {},
   "source": [
    "## Model Evaluation Based on Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ebbe2",
   "metadata": {},
   "source": [
    "How good is our selected model at correctly identifying _**above average**_ hitters, or better? If we consider the measure mentioned in the introduction, then one thought is looking at if the model is _generally_ good at identifying if a player is above average, or better.\n",
    "\n",
    "So, in this case, the question becomes less about what the specific value of the OPS is and more about if the player is predicted correctly as being above average (based on predicted Career OPS) or not.\n",
    "\n",
    "This last function is a test looking for the number of accurately classified players, in this general sense. For example, if a batter's predicted OPS is above average but their actual OPS is below average, then this would not be considered a correct prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a550a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_classification_accuracy(actual, prediction):\n",
    "    if len(actual) == len(prediction):\n",
    "        i = 0\n",
    "        correct_classifications = 0\n",
    "        \n",
    "        while i < len(actual):\n",
    "            actual_ops = actual[i]\n",
    "            predicted_ops = prediction[i]\n",
    "\n",
    "            if ((actual_ops > 0.7666) and (predicted_ops > 0.7666)) or \\\n",
    "                ((actual_ops <= 0.7666) and (predicted_ops <= 0.7666)):\n",
    "                correct_classifications += 1\n",
    "                \n",
    "            i+=1\n",
    "                \n",
    "    return correct_classifications/(len(actual)*1.0)\n",
    "\n",
    "\n",
    "general_classification_accuracy(y3_test, y3_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3503f9-1f40-460b-8904-da42e7e9f53a",
   "metadata": {},
   "source": [
    "What this metric shows us is that the model correctly identifies players as either above or below average 91.1% of the time.\n",
    "\n",
    "While it isn't a deeply meaningful metric, it is worth examining since it both confirms the model as _generally_ accurate model for this problem. Generally speaking, this appears to be an adequate model, albeit a very naive one in the larger world of baseball data and sabermetrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111444c1",
   "metadata": {},
   "source": [
    "## Comparison of the Hall of Fame Approach and the OPS Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02386c23",
   "metadata": {},
   "source": [
    "The OPS Approach is generally a good indicator of future batting success over a player's career, but not a stellar one. It is definitely more reliable than the Hall of Fame Approach for predicting batting success and is far more tangible in nature.\n",
    "\n",
    "The challenge with the Hall of Fame Approach is the very complicated world of selection and voting and things not on paper, statistically speaking, that play into whether or not a player is inducted. While at first thought it seemed like a valuable approach (after all, there aren't too many mediocre batters in the Hall of Fame) it was thoroughly flawed and not generally helpful for predicting those who will have moderate batting success throughout their careers but will not end up as Hall of Fame superstars.\n",
    "\n",
    "The surprise with the OPS Approach was how the strongest approach was to predict the Career OPS and not an OPS for a season that was more near-term in the future. The challenge with this approach is likely that of the many additional dynamics of play that it does not account for, even with respect to batting. For instance, a player may not have a high OPS but still be a very effective batter that contributes well to the team. This model would not be able to predict those player's successes at the plate because we were examining too specific of a measure. However, overall, this is a valuable, albeit imperfect, statistic for general use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
