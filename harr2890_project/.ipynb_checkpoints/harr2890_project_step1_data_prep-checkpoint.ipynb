{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469ffd13",
   "metadata": {},
   "source": [
    "# Using Historical Data to Predict Batting Success: Step 1 of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd96e6c",
   "metadata": {},
   "source": [
    "Authored by: Donna J. Harris (994042890)\n",
    "\n",
    "Email: harr2890@mylaurier.ca\n",
    "\n",
    "For: CP640 Machine Learning (S22) with Professor Elham Harirpoush"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3a7bb",
   "metadata": {},
   "source": [
    "## Project Introductory Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365c78b",
   "metadata": {},
   "source": [
    "Based on the project proposal of the same name, the _Using Historical Data to Predict Batting Success_ project demonstrates the process and exploration of Major League Baseball batting data from 1901 to 2021 to the end of discovering how or if historical data can be used to predict batting success.\n",
    "\n",
    "The Kaggle dataset being used as the primary data source can be found in the `data` folder of the project folder structure: `./data/mlbbatting1901-2021.csv`. The data in this dataset was originally sourced from data on Baseball-Reference.com, which is considered a leading authority on Major League Baseball statistics.\n",
    "\n",
    "Each data record in the original Kaggle dataset represents an individual batter's performance in a single game. This is why there are so many records. In a single game, there will be at least 18 batters with plate appearances across both teams, and often more with player substitutions, especially across extra innings. As a result, there is a lot of data processing and data validation required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e55ab",
   "metadata": {},
   "source": [
    "### Notebook Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459d55f",
   "metadata": {},
   "source": [
    "Just a word about the presentation of this project code.\n",
    "\n",
    "The code is organized into a series of locally executed Jupyter notebooks, organized by step and needing to be executed in sequence to follow the flow of the entire project.\n",
    "\n",
    "This direction was taken as it became easier to manage individual notebooks focussed on specific aspects of the project than to navigate one extremely large notebook.\n",
    "\n",
    "This is `harr2890_project_step1_data_prep`, the first of five notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b66900",
   "metadata": {},
   "source": [
    "### Two Approaches to Predicting Batting Success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2413a4",
   "metadata": {},
   "source": [
    "In the project proposal, exploring different approaches to predicting batting success was discussed as the goal for the project. While the thoughts at the time of writing the proposal didn't totally follow through into this project (more on that in the Project Report) the idea experimenting with different ideas did.\n",
    "\n",
    "As a result, there are two approaches:\n",
    "1. the Hall of Fame Approach (Steps 2 and 3)\n",
    "- `harr2890_project_step2_hof_data_prep`\n",
    "- `harr2890_project_step3_hof_modelling`\n",
    "2. the OPS Approach (Steps 4 and 5)\n",
    "- `harr2890_project_step4_ops_data_prep`\n",
    "- `harr2890_project_step5_ops_modelling`\n",
    "\n",
    "Both approaches require Step 1 (`harr2890_project_step1_data_prep`) to be completed first before running the notebooks associated with their steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba54d3e",
   "metadata": {},
   "source": [
    "## _**Step 1 - General Data Preparation**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea3ae57",
   "metadata": {},
   "source": [
    "This notebook encompasses the intial data preparation of the original source data and a supplemental data source. It is an essential step for all following notebooks and aspects of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e28c0",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f622eb",
   "metadata": {},
   "source": [
    "Import and establish environment for our work, including showing all dataframe column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c73aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf4620",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8811f",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac0cc5",
   "metadata": {},
   "source": [
    "First, we need to acquire the data from the Kaggle dataset and place into a dataframe.\n",
    "\n",
    "**Note:** this original data source remains zipped in the `kaggle_dataset` folder and should not be removed. The extracted data (and other data created by running these project notebooks) is saved to the `data` folder for use by following notebooks. The `data` folder and/or its contents can be erased, but doing so may require re-running one or more notebooks to regenerate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840bda33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "\n",
    "import zipfile\n",
    "\n",
    "mlb_zip = './kaggle_dataset/mlb-batting-stats-by-game-1901-2021.zip'\n",
    "original_data_source = './data/mlbbatting1901-2021.csv'\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(mlb_zip, mode='r') as archive:\n",
    "        archive.extractall('data/')\n",
    "        archive.close()\n",
    "except:\n",
    "    print(\"Error: Reading/unzipping the file.\")\n",
    "    \n",
    "df = pd.read_csv(original_data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d056d8a",
   "metadata": {},
   "source": [
    "Confirm the original data has been loaded into the data frame. (It should start with the earliest records from 1901 and end with the latest records from 2021.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65994ee",
   "metadata": {},
   "source": [
    "We have our confirmation that there are 31 columns and 4,285,629 data records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e12d88",
   "metadata": {},
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c103d",
   "metadata": {},
   "source": [
    "There is some data that might be of use to us that is trapped in existing columns. First, we want to extract the result of the game and the score of the game from the `'Rslt'` column. Then, we want to extract the year the game was played (denoting the season) from the `'Date'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Result','Score']] = df['Rslt'].str.split(' ', expand=True)\n",
    "df['Season'] = df['Date'].str[:4]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d92db9",
   "metadata": {},
   "source": [
    "### Column Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52f91b",
   "metadata": {},
   "source": [
    "There are a number of columns in the original dataset that we know before going any further that we have no use for.\n",
    "\n",
    "We no longer need `'Rslt'`, as we just split its interesting information into separate columns. Likewise with `'Date'`, we have what we need in the new `'Season'` column, so we can remove the `'Date'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598e4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del df['Rslt']\n",
    "del df['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b3184",
   "metadata": {},
   "source": [
    "Daily fantasy sports points (used for fantasy leagues and betting) have no purpose within this project, so we can safely remove `'DFS(DK)'` and `'DFS(FD)'` from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['DFS(DK)']\n",
    "del df['DFS(FD)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60674d8",
   "metadata": {},
   "source": [
    "Similarly, to reduce complexity, we are not considering any statistics relating to fielding or base running/stealing. As such, we can remove `'SB'` and `'CS'`, which are the number of stolen bases and time caught stealing, respectively, as well as the `'Pos Summary'` (position summary) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa88240",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['SB']\n",
    "del df['CS']\n",
    "del df['Pos Summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9278d",
   "metadata": {},
   "source": [
    "To further reduce complexity, we will remove the `'IBB'` (intentional walks) column as this is a subset of values tracked under the walks column (`'BB'`).  (Reference: https://en.wikipedia.org/wiki/Base_on_balls#Intentional_base_on_balls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be353fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['IBB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbec4f",
   "metadata": {},
   "source": [
    "We can remove the `'GDP'` column, which represents the number of times a player hits into a double play (two outs). While this statistic has some bearing to the success of a batter, for this project we will exclude this nuance and focus more on the aspects of run production and getting on base through other statistical means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc906eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['GDP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9935c43",
   "metadata": {},
   "source": [
    "Similarly to `'GDP'`, we will disregard the `'ROE'` column, which represents the number of times a player reaches base due to a fielding error by the opposing team. Like `'GDP'`, this statistic has some bearing to the success of a batter but it leans more toward their running abilities and street smarts of the player, as well as a bit of luck. Again, for this project, these nuances will be excluded for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac17286",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['ROE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce2442",
   "metadata": {},
   "source": [
    "Before continuing on to value checking, let's look and see where the data is at after these processing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944eced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563b189",
   "metadata": {},
   "source": [
    "We added three new columns (`'Result'`, `'Score'`, and `'Season'`) -- which we may or may not need later -- and also removed ten existing columns. So, this looks correct: 31 original features + 3 new features - 11 features = 23 feature columns.\n",
    "\n",
    "We still have 4,285,629 data records, as we have not removed any records yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93ddab",
   "metadata": {},
   "source": [
    "### Value Checking and Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c16340",
   "metadata": {},
   "source": [
    "**ID - Player ID**\n",
    "\n",
    "Should be unique to each player. This will indicate how many players we currently have, based on player ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995c267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "player_ids = pd.unique(df['ID'])\n",
    "print(player_ids)\n",
    "\n",
    "print(\"\\nNumber of unique player IDs: \", len(player_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1cf467",
   "metadata": {},
   "source": [
    "**Player - Player Name**\n",
    "\n",
    "Should be roughly the same number of player IDs. Discrepancies are possible, errors in spelling, etc. but this is not highly significant for our statistics since we will key everything on the more reliable Player ID. We will hang onto this field to help humanly identify players by name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c969ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['Player']))\n",
    "\n",
    "print(\"\\nNumber of unique player names: \", len(pd.unique(df['Player'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e7744",
   "metadata": {},
   "source": [
    "**Note:** We found there were 15,985 unique IDs and 15,595 unique player names, which is a difference of 390 in favour of the IDs. This could easily be explained by different players over the years with the same name. This is a nuance that will be disregarded for this project. As previously stated, we will use the ID for all but human identification purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ee4b0",
   "metadata": {},
   "source": [
    "**Season - Year the game was played in**\n",
    "(Extracted from `'Date'`)\n",
    "\n",
    "The values should all be visibly in YYYY format between the years of 1901 and 2021, inclusive.\n",
    "\n",
    "Ideally, these values will be Integers -- but they have started as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a14e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.unique(df['Season']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549f0622",
   "metadata": {},
   "source": [
    "We can see visibly that these values are all YYYY integers, so let's convert them to actual integers in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f92bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Season'] = df['Season'].astype(int)\n",
    "\n",
    "# test\n",
    "print(pd.unique(df['Season']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10c38f",
   "metadata": {},
   "source": [
    "**Tm - Player's Team** and **Opp - Opponent**\n",
    "\n",
    "The team values (both the player's team and the opposing team) should all be visibly in ZZZ format, belonging to a recognizable team between the 1901-2021 seasons. These are fields that will likely get dropped later on, but I'm keeping them until I know for sure I don't want them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Player's Team (Tm):\\n\", pd.unique(df['Tm']))\n",
    "print(\"\\nOpposing Team (Opp):\\n\", pd.unique(df['Opp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c391c2d",
   "metadata": {},
   "source": [
    "**PA - Plate Appearances**\n",
    "\n",
    "Appearances should be an integer value, between the range of 1 and some upper value. (A 0 would indicate the player didn't bat in the game which would mean there should not be a record.)\n",
    "\n",
    "The upper value will vary, although (speaking as a baseball fan) five plate appearances is pretty standard in a regular, nine-inning, low scoring game. But as soon as you get into higher scores and/or extra inning games, players can be up to bat many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71076a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['PA']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e7c8f2",
   "metadata": {},
   "source": [
    "**Note:** 12 was the upper value. I'm curious of what era these are from, so let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['PA'] == 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56951a7",
   "metadata": {},
   "source": [
    "**AB - At Bats**\n",
    "\n",
    "Similarly to Plate Appearances, At Bats should be an integer value. It should be between the range of 0 and some upper value. (Here, a 0 would indicate the player had one plate appearance that did not statistically count as an At Bat, such as a walk.)\n",
    "\n",
    "The upper range should follow, and not exceed the upper value of Plate Appearances, which was 12. Note that 12 is possible, but does not have to be a value in this collection of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['AB']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95c36c",
   "metadata": {},
   "source": [
    "**Note:** 11 was the upper value, which is less then 12. (The max number of plate appearances.)\n",
    "\n",
    "We should validate that there are no records where there are more At Bats than Plate Appearances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1fb2d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------\")\n",
    "print(\"All records with PA < AB\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(df[df['PA'] < df['AB']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7e62f",
   "metadata": {},
   "source": [
    "**Note:** The validation checks pass, as we have found no records where PA < AB. No extra investigation or validation is required here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07132903",
   "metadata": {},
   "source": [
    "**R - Runs**\n",
    "\n",
    "Runs should also be an integer value, in the range of 0 and some upper value. The upper value can be, at most, one larger than the number of plate appearances. In general, that's 12+1 for this dataset, but that's a highly unlikely value to see as number of runs. (We'll address individual records in the next step.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d378404",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['R']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3e85b",
   "metadata": {},
   "source": [
    "**Note:** We want to do some validation within each individual data record to look for instances where the number of plate appearances is less than the number of runs (e.g., when a player pinch runs for a teammate and then scores a run they have 0 plate appearances and 1 run). And within that subset of records, look for instances where there is more than a difference of one between the `'PA'` and `'R'` values. (If we find any instances with a difference larger than one, we may have a data issue.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_r = df[df['PA'] < df['R']]\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"All records with PA < R\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a7f40",
   "metadata": {},
   "source": [
    "Here, we see records where PA < R, so now we'll do a check to see if there are any instances within this subset of records where there is more than 1 run difference from the number of plate appearances. If we don't have any instances, then our investigation here ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9e301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n-----------------------------------------\")\n",
    "print(\"All records with PA < R where PA != R-1\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_r[ records_pa_lt_r['PA'] != ((records_pa_lt_r['R']-1)) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d18eb5",
   "metadata": {},
   "source": [
    "**Note:** The validation checks pass, as we have found no records where PA < R and PA != R-1. No extra investigation or validation is required here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4378568",
   "metadata": {},
   "source": [
    "**H - Hits**\n",
    "\n",
    "Hits should also be an integer value, in the range of 0 and some upper value. The upper value can be, at most, the number of plate appearances. In general, that's 12 for this dataset, but that's a highly unlikely value to see as number of hits. (We'll address individual records in the next step.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['H'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4c1ee",
   "metadata": {},
   "source": [
    "**Note:** We should also confirm that there are never more hits than plate appearances within individual records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_h = df[df['PA'] < df['H']]\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"All records with PA < H\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a50cd9",
   "metadata": {},
   "source": [
    "**Note:** The validation checks pass, as we have found no records where PA < H. No extra investigation or validation is required here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81b7e3",
   "metadata": {},
   "source": [
    "**2B - Doubles**\n",
    "**3B - Triples**\n",
    "**HR - Home Run**\n",
    "\n",
    "All of these extra base hits must be integer values, within the range of 0 up to the number of Plate Appearances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2B: \", pd.unique(df['2B']))\n",
    "print(\"3B: \", pd.unique(df['3B']))\n",
    "print(\"HR: \", pd.unique(df['HR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af2b640",
   "metadata": {},
   "source": [
    "**Note:** These are all reasonable values at a glance.\n",
    "\n",
    "We should also confirm that these values are never greater than the number of Plate Appearances, At Bats, or Hits within individual records. (Note that Hits (`'H'`) represents all kinds of hits, not just single-base hits.)\n",
    "\n",
    "We will do this for the next several code blocks, then regroup with next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1beb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_2b = df[df['PA'] < df['2B']]\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"All records with PA < 2B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd2df7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_pa_lt_3b = df[df['PA'] < df['3B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < 3B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_hr = df[df['PA'] < df['HR']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < HR\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267f7ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_ab_lt_2b = df[df['AB'] < df['2B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < 2B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f664b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_ab_lt_3b = df[df['AB'] < df['3B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < 3B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c33c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_ab_lt_hr = df[df['AB'] < df['HR']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < HR\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_h_lt_2b = df[df['H'] < df['2B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with H < 2B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_h_lt_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa63d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_h_lt_3b = df[df['H'] < df['3B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with H < 3B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_h_lt_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_h_lt_hr = df[df['H'] < df['HR']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with H < HR\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_h_lt_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10054d",
   "metadata": {},
   "source": [
    "**Note:** These validation checks caught a couple of problematic records. Looking at the entirety of these records, it looks like a simple data error, where the number of Hits needs to be updated to reflect the number of extra base hits. Instead of removing all records for these players, we will make these small data adjustments.\n",
    "\n",
    "There are two players and two specific games that seem to be impacted by this issue, Ed Robinson and Joe Tipton. Let's clean these up and then test again.\n",
    "\n",
    "**First for Ed Robinson**, directly using the record index in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_robinson = 1275367\n",
    "\n",
    "df.loc[[ed_robinson]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e79a8",
   "metadata": {},
   "source": [
    "For **Ed Robinson's record** (1275367), we will use the doubles (`'2B'`) statistic value as the value for Hits, Plate Appearances, and At Bats. These are reasonable guesses, based on the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9082b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[ed_robinson, 'H'] = df.at[ed_robinson, '2B']\n",
    "df.at[ed_robinson, 'AB'] = df.at[ed_robinson, '2B']\n",
    "df.at[ed_robinson, 'PA'] = df.at[ed_robinson, '2B']\n",
    "\n",
    "df.loc[[ed_robinson]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62788d1a",
   "metadata": {},
   "source": [
    "**Next for Joe Tipton**, again, directly using the record index in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76926b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_tipton = 1272928\n",
    "\n",
    "df.loc[[joe_tipton]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d106924",
   "metadata": {},
   "source": [
    "For **Joe Tipton's record** (1272928), we will use the triples (`'3B'`) statistic value as the value for Hits but it is possible that the statistics for Plate Appearances and At Bats is correct. Because it is not obviously wrong, we won't change these. These are reasonable guesses, based on the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[joe_tipton, 'H'] = df.at[joe_tipton, '3B']\n",
    "\n",
    "df.loc[[joe_tipton]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e06655",
   "metadata": {},
   "source": [
    "**Re-testing the original checks**\n",
    "\n",
    "Re-running the tests that found these data issues should now pass and not introduce any new issues, including the checks the passed the first time to ensure we didn't introduce new issues for these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76eb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_2b = df[df['PA'] < df['2B']]\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"All records with PA < 2B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_3b = df[df['PA'] < df['3B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < 3B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_hr = df[df['PA'] < df['HR']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < HR\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc871f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_ab_lt_2b = df[df['AB'] < df['2B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < 2B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6090b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_ab_lt_3b = df[df['AB'] < df['3B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < 3B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4618a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_ab_lt_hr = df[df['AB'] < df['HR']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < HR\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_h_lt_2b = df[df['H'] < df['2B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with H < 2B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_h_lt_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_h_lt_3b = df[df['H'] < df['3B']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with H < 3B\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_h_lt_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_h_lt_hr = df[df['H'] < df['HR']]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with H < HR\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_h_lt_hr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db6fac",
   "metadata": {},
   "source": [
    "**SUCCESS!!** The previous data issues have been resolved. `'2B'`, `'3B'`, and `'HR'` are now validated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91536b6",
   "metadata": {},
   "source": [
    "**RBI - RBIs (Runs Batted In)**\n",
    "\n",
    "This is an important statistic, especially for calculated batting statistics which may prove useful later.\n",
    "\n",
    "RBIs should be an integer value, in the range of 0 and some upper value. The upper value is dependent on the number of runners on base at the time of the plate appearance, which we do not know directly from the data. We can estimate a maximum possible value of Plate Appearances * 4 (the maximum number of runs possible to bat in). This maximum value would be statistically possible but highly unlikely. But it means that if we see a value higher than 12 * 4 = 48 in a single game then it is definitely out of range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['RBI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7229dcc",
   "metadata": {},
   "source": [
    "**Note:** Of course, we don't see anything nearly as extreme as 48, but we have multiple problems here: (1) RBI is stored as a Float value, which makes no sense in this context, and (2) we have a NaN/undefined value to deal with.\n",
    "\n",
    "While it would be nice to convert to integer values, the presence of NaN values blocks our carrying out this operation. So, first, we have to make a decision about how to deal with the NaN values.\n",
    "\n",
    "Let's look at how many records include these NaN values and how many unique players are impacted by this data issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77402474",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbi_is_nan = df.loc[pd.isna(df['RBI'])]\n",
    "rbi_is_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95af887",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUnique Players with this RBI-NaN problem:\")\n",
    "rbi_nan_players = pd.unique(rbi_is_nan['ID'])\n",
    "print(rbi_nan_players)\n",
    "print(\"Count: \",len(rbi_nan_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7bced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPercentage of overall records (\",len(df),\") impacted: \", len(rbi_is_nan)/len(df)*100)\n",
    "print(\"There are\",len(rbi_nan_players),\"players impacted by these\",len(rbi_is_nan),\"records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a0597",
   "metadata": {},
   "source": [
    "While the number of overall records impacted is less than 1%, we see that there are many more players than there are records with this problem, which means that it is safest to remove all records for these players -- not only the problematic ones. Since all of the impacted data records are from seasons early in the 20th century, this does not raise any great concerns for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beedf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the removal\n",
    "df = df[df['ID'].isin(rbi_nan_players) == False].copy()\n",
    "\n",
    "# test\n",
    "print(\"\\nTest for an empty list of RBI==NaN values, after removing rows:\\n\\n\", df.loc[pd.isna(df['RBI'])])\n",
    "print(\"\\n\\nReduced to\",len(df),\"records in main data frame after removing those players records entirely.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092e4ab",
   "metadata": {},
   "source": [
    "**Finally,** we can address our other issue: converting the type for RBI from float to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ecbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RBI'] = df['RBI'].astype(int)\n",
    "\n",
    "# test\n",
    "print(pd.unique(df['RBI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c4d28",
   "metadata": {},
   "source": [
    "**SUCCESS!!** No NaN values and all Integer values. And all of these are reasonable values at a glance.\n",
    "\n",
    "We should also confirm that RBI values are never greater than the number of Plate Appearances within individual records. (Note: There are many different scenarios for earning an RBI, but they all require a corresponding Plate Appearance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41759113",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa4_lt_rbi = df[df['PA']*4 < (df['RBI']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA*4 < RBI\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa4_lt_rbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c350a1",
   "metadata": {},
   "source": [
    "**Note:** All RBI-related data issues have been resolved and our check within a record has passed. `'RBI'` is now validated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4dfd5",
   "metadata": {},
   "source": [
    "**BB - Base On Balls (Walks)**\n",
    "\n",
    "Walks should be an integer value, within the range of 0 up to the number of Plate Appearances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['BB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bea0b",
   "metadata": {},
   "source": [
    "**Note:** These are all reasonable values at a glance.\n",
    "\n",
    "We should also confirm that Walk values are never greater than the number of Plate Appearances within individual records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25def045",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_bb = df[df['PA'] < (df['BB']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < BB\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df435d",
   "metadata": {},
   "source": [
    "**HBP - Hit By Pitch**\n",
    "\n",
    "Hit By Pitch should be an integer value, within the range of 0 up to the number of Plate Appearances.\n",
    "\n",
    "Reference: https://en.wikipedia.org/wiki/Base_on_balls\n",
    "HBP is **not** recorded as a walk/BB. (\"A hit by pitch is not counted statistically as a walk, though the effect is mostly the same, with the batter receiving a free pass to first base.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['HBP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdba10a",
   "metadata": {},
   "source": [
    "**Note:** These are all reasonable values at a glance.\n",
    "\n",
    "We should also confirm that HBP values are never greater than the number of Plate Appearances within individual records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_hbp = df[df['PA'] < (df['HBP']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < HBP\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_hbp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ec156",
   "metadata": {},
   "source": [
    "**SO - Strikeouts**\n",
    "\n",
    "Strikeouts should be an integer value, within the range of 0 up to the number of Plate Appearances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['SO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc9439",
   "metadata": {},
   "source": [
    "**Note:** These are all reasonable values at a glance.\n",
    "\n",
    "We should also confirm that Strikeout values are never greater than the number of Plate Appearances or At Bats within individual records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_so = df[df['PA'] < (df['SO']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < SO\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da139ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_ab_lt_so = df[df['AB'] < (df['SO']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < SO\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d744358",
   "metadata": {},
   "source": [
    "**Note:** We found one record (Owen Friend) with a strikeout but no at bats -- which doesn't make sense.\n",
    "\n",
    "Let's address this record, directly by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa14f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "owen_friend = 1252967\n",
    "df.loc[[owen_friend]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f79942",
   "metadata": {},
   "source": [
    "Looking closer we can make a minor data adjustment for this record, and assume that there should be two At Bats instead of 0. In this game, the player stuck out once -- which means there was at least one At Bat.\n",
    "\n",
    "Note: we also see a sacrifice hit (`'SH'`) listed. But, Sacrifice Hits and Flies (`'SF'`) do not count as times At Bat. They do, however, count as Plate Appearances.\n",
    "\n",
    "These statistics demonstrate there must have been at least one At Bat. There was also one Walk (`'BB'`), which should mean there was at least three Plate Appearances, between the Sacrifice Hit, the Walk, and the Strikeout.\n",
    "\n",
    "The most reasonable guess here is to set PA = 3 and AB = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[owen_friend, 'PA'] = 3\n",
    "df.at[owen_friend, 'AB'] = 1\n",
    "\n",
    "df.loc[[owen_friend]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061adba",
   "metadata": {},
   "source": [
    "Re-Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bbc33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_pa_lt_so = df[df['PA'] < (df['SO']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < SO\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa466dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records_ab_lt_so = df[df['AB'] < (df['SO']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with AB < SO\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_ab_lt_so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a101138d",
   "metadata": {},
   "source": [
    "**Note:** Re-testing was succesful and the issue with this record is resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84c0c9",
   "metadata": {},
   "source": [
    "**SH - Sacrifice Hits**\n",
    "\n",
    "Sacrifice Hits should be an integer value, within the range of 0 up to the number of Plate Appearances.\n",
    "\n",
    "Note: Sacrifice plays do not count against the batter and, as such, don't count as At Bats.\n",
    "\n",
    "References:\n",
    "https://www.mlb.com/glossary/standard-stats/sacrifice-bunt\n",
    "https://www.baseball-reference.com/bullpen/Sacrifice_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['SH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723d40c",
   "metadata": {},
   "source": [
    "**Note:** These are all reasonable values at a glance.\n",
    "\n",
    "We should also confirm that Sacrifce Hits values are never greater than the number of Plate Appearances within individual records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3300b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_sh = df[df['PA'] < (df['SH']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < SH\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40135ab7",
   "metadata": {},
   "source": [
    "**SF - Sacrifice Flies**\n",
    "\n",
    "Sacrifice Flies should be an integer value, within the range of 0 up to the number of Plate Appearances.\n",
    "\n",
    "Note: Sacrifice plays do not count against the batter and, as such, don't count as At Bats.\n",
    "\n",
    "Reference:\n",
    "https://www.mlb.com/glossary/standard-stats/sacrifice-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['SF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604a193",
   "metadata": {},
   "source": [
    "**Note:** We find that our Sacrifice Flies data is non-integer -- as with the RBI data processing, this is because there are NaN values present.\n",
    "\n",
    "We will take the same approach for investigation, record removal, and conversion as with RBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9a501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_is_nan = df.loc[pd.isna(df['SF'])]\n",
    "sf_is_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791c754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nUnique Players with this SF-NaN problem:\")\n",
    "sf_nan_players = pd.unique(sf_is_nan['ID'])\n",
    "print(sf_nan_players)\n",
    "print(\"Count: \",len(sf_nan_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb443cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPercentage of overall records (\",len(df),\") impacted: \", len(sf_is_nan)/len(df)*100)\n",
    "print(\"There are\",len(sf_nan_players),\"players impacted by these\",len(sf_is_nan),\"records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1ad13",
   "metadata": {},
   "source": [
    "We see here that a much larger percentage of our dataset is impacted (21%), so before removing all of these records and all of the player data associated, we need to consider the potential importance of the Sacrifice Flies feature for the project.\n",
    "\n",
    "Removing the SF column itself is not an option if we want to calculate the OBP (On Base Percentage) statistic, which is required for calculating the OPS (On Base Plus Slugging) statistic.\n",
    "\n",
    "Instead of NaN values, we will replace the NaN values with zeroes. It won't be accurate in all cases (since these haven't always been tracked), but the worst case will be that the affected records will underreport this statistic and consequently have a lower OBP percentage. But, it is the best we can do without completely removing the data.\n",
    "\n",
    "In this processing, we'll also convert the field to an Integer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddec639",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_of_sf = sf_is_nan.index\n",
    "series_of_sf\n",
    "\n",
    "df.loc[series_of_sf, 'SF'] = 0\n",
    "df['SF'] = df['SF'].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e3fa7",
   "metadata": {},
   "source": [
    "Let's check `SF` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ddc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['SF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81d85d",
   "metadata": {},
   "source": [
    "Now that's looking better, let's do the customary check to see that there aren't more sacrifice flies (`SF`) than there are plate appearances `PA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d98554",
   "metadata": {},
   "outputs": [],
   "source": [
    "records_pa_lt_sf = df[df['PA'] < (df['SF']) ]\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(\"All records with PA < SF\")\n",
    "print(\"-----------------------------------------\")\n",
    "records_pa_lt_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d84fb9",
   "metadata": {},
   "source": [
    "### Advanced Statistics in the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1295ff",
   "metadata": {},
   "source": [
    "There are three more modern, advanced statistics that were included in the original dataset: `WPA`, `RE24` and `aLI`. As we have worked through the data, it has been common to notice these fields have had NaN values for earlier records. Before how to proceed with these three statistics in our data, let's look more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac1df3",
   "metadata": {},
   "source": [
    "**WPA - Win Probability Added**\n",
    "\n",
    "Reference:\n",
    "https://en.wikipedia.org/wiki/Win_probability_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['WPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebaec04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wpa_is_nan = df.loc[pd.isna(df['WPA'])]\n",
    "wpa_is_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUnique Players with this SF-NaN problem:\")\n",
    "wpa_nan_players = pd.unique(wpa_is_nan['ID'])\n",
    "print(wpa_nan_players)\n",
    "print(\"Count: \",len(wpa_nan_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30635e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPercentage of overall records (\",len(df),\") impacted: \", len(wpa_is_nan)/len(df)*100)\n",
    "print(\"There are\",len(wpa_nan_players),\"players impacted by these\",len(wpa_is_nan),\"records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b2ac4",
   "metadata": {},
   "source": [
    "**RE24 - Base-Out Runs Added**\n",
    "\n",
    "This statistic represents the run expectancy based on 24 base outs.\n",
    "\n",
    "Reference:\n",
    "https://thebaseballscholar.com/2017/08/14/sabermetrics-101-re24/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['RE24'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfa539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re24_is_nan = df.loc[pd.isna(df['RE24'])]\n",
    "re24_is_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a775a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUnique Players with this SF-NaN problem:\")\n",
    "re24_nan_players = pd.unique(re24_is_nan['ID'])\n",
    "print(re24_nan_players)\n",
    "print(\"Count: \",len(re24_nan_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596db349",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPercentage of overall records (\",len(df),\") impacted: \", len(re24_is_nan)/len(df)*100)\n",
    "print(\"There are\",len(re24_nan_players),\"players impacted by these\",len(re24_is_nan),\"records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd33ed5",
   "metadata": {},
   "source": [
    "**aLI - Average Leverage Index**\n",
    "\n",
    "Reference:\n",
    "https://www.azsnakepit.com/2021/11/9/22742763/what-average-leverage-index-revealed-about-the-2021-diamondbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['aLI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335b691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ali_is_nan = df.loc[pd.isna(df['aLI'])]\n",
    "ali_is_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUnique Players with this SF-NaN problem:\")\n",
    "ali_nan_players = pd.unique(ali_is_nan['ID'])\n",
    "print(ali_nan_players)\n",
    "print(\"Count: \",len(ali_nan_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPercentage of overall records (\",len(df),\") impacted: \", len(ali_is_nan)/len(df)*100)\n",
    "print(\"There are\",len(ali_nan_players),\"players impacted by these\",len(ali_is_nan),\"records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb2886",
   "metadata": {},
   "source": [
    "**Note:** An interesting phenomenon was seen with the WPA, RE24, and aLI statistics. They all seem to have been calculated in a similar range of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0702e9",
   "metadata": {},
   "source": [
    "***A DECISION ... FOR WPA, RE24, and aLI STATISTICS***\n",
    "\n",
    "After looking at all of this data, the nature of the statistics, and the goals of this project, the best decision is to remove these three features entirely. These three statistics are quite advanced to a point that is beyond the scope of this project.\n",
    "\n",
    "So, we will remove these columns from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['WPA']\n",
    "del df['RE24']\n",
    "del df['aLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8501d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96a42d",
   "metadata": {},
   "source": [
    "Considering what remains, `'BOP'` (Batting Order Position) and the extracted `'Score'`, I do not foresee any use for either of these, so I will remove these columns as well.\n",
    "\n",
    "At this time, I have decided to keep the `'Tm'` and `'Opp'` columns in the data for context but do not anticipate using it in any of the learning aspects of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['BOP']\n",
    "del df['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4deddf",
   "metadata": {},
   "source": [
    "**Result**\n",
    "\n",
    "I am intentionally keeping `'Result'` at this time, so that I have options if I want to later look at how many winning games a player participated in, although there is a good chance this level of nuance will end up being outside of the scope of the project.\n",
    "\n",
    "These values are extracted strings and should be one of 3 values: \"W\", \"L\", or \"T\". (Note that \"T\" represents a tied game, which is relatively unusual in baseball.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df['Result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418f57a",
   "metadata": {},
   "source": [
    "### It's Time to Save The Core MLB Data to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e1a28",
   "metadata": {},
   "source": [
    "We've done all this work to clean and validate the data, and once we've got it right we don't need to do it again, unless we're making improvements. So, since there's still a lot of processing and manipulation to come based on this version of the data, this is the moment we will save it and then additional notebooks will move forward, starting with the MLB batting data in this format.\n",
    "\n",
    "We will save it to the `data` folder in the project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee166c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_mlb_dataset = \"./data/core_mlb_dataset.csv\"\n",
    "df.to_csv(core_mlb_dataset, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa542c9",
   "metadata": {},
   "source": [
    "# Getting the Supplemental Hall of Fame Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa90ad",
   "metadata": {},
   "source": [
    "One of my initial ideas to explore is mapping historical player data to inductees to the Hall of Fame and then using it to attempt predictions for Hall of Fame inductees, based on batting data alone.\n",
    "\n",
    "This data was extracted from Baseball-Reference.com, which is also the original source of the Kaggle dataset chosen for this project. As a result, the Hall of Fame inductee list has the same IDs as the batting data, making it relatively easy to align the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a1afb",
   "metadata": {},
   "source": [
    "The data file is stored in the project folder `supplemental_data` and was exported from https://www.baseball-reference.com/awards/hof.shtml into a file I named `hall_of_famers.csv`.\n",
    "\n",
    "Reading in the file and displaying the file contents we find the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75768783",
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_data = pd.read_csv('./supplemental_data/hall_of_famers.csv')\n",
    "hof_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793853a",
   "metadata": {},
   "source": [
    "On examination of the file, we see that there is some work to do to isolate the information we're interested in.\n",
    "\n",
    "For instance, the `Name` column contains two pieces of information we are familiar with in the main dataset: `Player` and `ID`. So, we extract these fields into their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7aae73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hof_data[['Player','ID']] = hof_data['Name'].str.split('\\\\', expand=True)\n",
    "hof_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b73784",
   "metadata": {},
   "source": [
    "Next, we want to learn more about the contents of the `Inducted As` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(hof_data['Inducted As'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde44e5d",
   "metadata": {},
   "source": [
    "We're only interested in players, so we'll want to filter that down.\n",
    "\n",
    "First, let's simplify the dataframe by reducing it to the two columns of interest: `ID` and `Inducted As`. We are looking for a list of IDs only, because we know the names in the main table. We're also not concerned with details about when the player was active or inducted, or other details about how they were inducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ID', 'Inducted As']\n",
    "hof_data = hof_data[cols].copy()\n",
    "hof_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e354185",
   "metadata": {},
   "source": [
    "Next, we'll filter down the list of inductees based on them being inducted as a player, which indicates they had a special measure of success as a player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fdb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "hof_data = hof_data[hof_data['Inducted As'] == 'Player'].copy()\n",
    "hof_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcaf98",
   "metadata": {},
   "source": [
    "Finally, we will remove the `Inducted As` column, but add a classifying category of `Inductee` and set all records in the dataframe as `1`, since all players on the list are in the Hall of Fame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57558e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del hof_data['Inducted As']\n",
    "hof_data['Inductee'] = 1\n",
    "hof_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79505ab",
   "metadata": {},
   "source": [
    "### It's Time to Save The Supplemental Hall of Fame Data to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff289b23",
   "metadata": {},
   "source": [
    "Just like we did with the core MLB batting data, let's do a quick save to file of the data in this format. We still have more to do with it when we want to merge it with some aspect of the core data, but this is an important state to capture it in for future experiments.\n",
    "\n",
    "We will save it to the `data` folder in the project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42087c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "    \n",
    "hof_dataset = \"./data/hof_dataset.csv\"\n",
    "hof_data.to_csv(hof_dataset, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263537fb",
   "metadata": {},
   "source": [
    "## Concluding Notebook Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46e9ec",
   "metadata": {},
   "source": [
    "**Note:** At this point, we will conclude this notebook for organizational purposes, as it is quite lengthy with all of the data validation work in particular.\n",
    "\n",
    "Saving the data files in various states makes it easier to re-run parts of the overall project without having to re-run every aspect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0bf37c",
   "metadata": {},
   "source": [
    "The **purpose of this notebook** is to extract the original and supplemental data from the original sources, investigate, organize, validate, and initially prepare the data for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d56ae",
   "metadata": {},
   "source": [
    "**The *next* notebook in the series is: `harr2890_project_step2_hof_data_prep`,** where the saved, data files will be loaded and data preparation will continue with the structuring and splitting up the data for the purposes of experimentation and modelling in a subsequent notebook dealing with the **Hall of Fame Approach**.\n",
    "\n",
    "However, the `harr2890_project_step4_ops_data_prep` notebook also uses the data generated at this step. So, **if one is only running the OPS Approach**, steps 2 and 3 can be skipped after completing this step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
